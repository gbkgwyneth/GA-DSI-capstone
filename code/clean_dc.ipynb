{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:#3b748a'>The rental data for DC is TOO large to upload to GitHub.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/bikes_banner.jpg\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#37535e\">Bicycle Share Usage</span>\n",
    "\n",
    "##  <span style='color:#3b748a'>Cleaning Capital Bikeshare data</span>\n",
    "\n",
    "<span style='color:#4095b5'>In this notebook, we load and clean 12 months (Sep 2017 - July 2018) data from the Washington DC bicycle share. The data is quarterly for 2017 and monthly for 2018. There is data going back to 2010 that we can clean and use if it seems useful. For now we will use 12 months of data.</span>\n",
    "\n",
    "<span style='color:#4095b5'>Each row (observation) of data describes one bike ride on which a bike is taken. Each trip includes a starting place and time, an ending place and time, as well as duration, user, and bike information. </span>\n",
    "\n",
    "<span style='color:#4095b5'>We start with TODO rentals and TODO columns and clean to TODO rows and TODO columns. Almost 8K of the observations dropped were rentals of trivial duration (less than 3 minutes).</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#3b748a'>Table of contents</span>\n",
    "* <span style='color:#4095b5'>I.  <a href=\"#checking\"><span style='color:#4095b5'>Data checking functions.</span></a></span>\n",
    "* <span style='color:#4095b5'>II. <a href=\"#cleaning\"><span style='color:#4095b5'>Data cleaning functions.</span></a></span>\n",
    "* <span style='color:#4095b5'>III. <a href=\"#import\"><span style='color:#4095b5'>Create hub data.</span></a></span>\n",
    "* <span style='color:#4095b5'>IV. <a href=\"#import\"><span style='color:#4095b5'>Extract July, Aug, Sep 2017 from 2017 Q3 data.</span></a></span>\n",
    "* <span style='color:#4095b5'>V. <a href=\"#import\"><span style='color:#4095b5'>Import all data.</span></a></span>\n",
    "* <span style='color:#4095b5'>VI. <a href=\"#clean\"><span style='color:#4095b5'>Clean all data.</span></a></span>\n",
    "* <span style='color:#4095b5'>VII. <a href=\"#merge\"><span style='color:#4095b5'>Merge the dataframes into 1 big one.</span></a></span>\n",
    "* <span style='color:#4095b5'>VIII. <a href=\"#explore\"><span style='color:#4095b5'>Explore the data.</span></a></span>\n",
    "* <span style='color:#4095b5'>IX. <a href=\"#write\"><span style='color:#4095b5'>Write the full DataFrame to a csv file.</span></a></span>\n",
    "\n",
    "## <span style='color:#3b748a'>Links</span>\n",
    "* <a href=\"https://www.capitalbikeshare.com/system-data\"><span style='color:#4095b5'>DC Capital Bikeshare data</span></a>\n",
    "* <a href=\"main.ipynb\">Main notebook</a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the administrative stuff done first\n",
    "# import all the libraries and set up the plotting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "# Gloabal variables to track \n",
    "trivial_duration = 0\n",
    "trivial_distance = 0\n",
    "outliers_latlon = 0\n",
    "outliers_duration = 0\n",
    "outliers_distance = 0\n",
    "\n",
    "# GnBu_d\n",
    "colors = ['#37535e', '#3b748a', '#4095b5', '#52aec9', '#72bfc4', '#93d0bf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"checking\"> </a>\n",
    "## <span style='color:#3b748a'>I. Data checking functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which non-numeric columns are missing values and what the possible values are for each object column\n",
    "\n",
    "def check_cols(df):\n",
    "    cols = df.select_dtypes([np.object]).columns\n",
    "    for col in cols:\n",
    "        print(\"{} is {} and values are {}.\".format(col,df[col].dtype,df[col].unique()))\n",
    "        n_nan = df[col].isnull().sum()\n",
    "        if n_nan > 0:\n",
    "            print(\"{} has {} NaNs\".format(col,n_nan))\n",
    "            \n",
    "    cols = df.select_dtypes([np.int64,np.float64,np.uint64]).columns\n",
    "    for col in cols:\n",
    "        print(\"{} is {} and values are {} to {}.\".format(col,df[col].dtype,df[col].min(),df[col].max()))\n",
    "        n_nan = df[col].isnull().sum()\n",
    "        if n_nan > 0:\n",
    "            print(\"{} has {} NaNs\".format(col,n_nan))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which numeric columns are missing values\n",
    "\n",
    "def check_data(df):\n",
    "    s = df.shape\n",
    "\n",
    "    # Check for null values\n",
    "    null_data = df.isnull().sum()\n",
    "    null_data_count = sum(df.isnull().sum())\n",
    "    print(\"Rows: {}\\t Cols: {}\\t NaNs: {}\".format(s[0],s[1],null_data_count))\n",
    "    if  null_data_count > 0:\n",
    "        print(\"Columns with NaN: {}\".format(list(null_data[null_data > 0].index)))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"cleaning\"></a>\n",
    "## <span style='color:#3b748a'> II. Data cleaning functions</span>\n",
    "\n",
    "<span style='color:#4095b5'>These functions clean the trip data.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Drop columns *NOT* in Atlanta data.</span>\n",
    "<span style='color:#52aec9'>I might want to add some back at some point.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    cols_drop = ['Start station number', 'End station number', 'Member type']\n",
    "\n",
    "    # Can't drop a column that isn't there\n",
    "    cols_drop = list(set(df.columns) & set(cols_drop))\n",
    "    df.drop(cols_drop, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Rename columns to match Atlanta data names.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    df.rename(columns={'Start station' : 'Start Hub', \n",
    "                   'Start date' : 'Start Time', \n",
    "                   'End station' : 'End Hub', \n",
    "                   'End date' : 'End Time', \n",
    "                   'Bike number' :'Bike Name',\n",
    "                   'Duration' : 'Duration'\n",
    "                  }, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Merge with hub data.</span>\n",
    "<span style='color:#52aec9'>We may have to use the start/end hubs to get start/end lat/long.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_latlong(df, df_hubs):\n",
    "    df = df.merge(df_hubs, left_on='Start Hub', right_on='Hub', how='left')\n",
    "    df.drop('Hub', axis = 1, inplace=True)\n",
    "    df.rename(columns={'Latitude' : 'Start Latitude', \n",
    "                       'Longitude' : 'Start Longitude'\n",
    "                      }, inplace=True)\n",
    "\n",
    "    df = df.merge(df_hubs, left_on='End Hub', right_on='Hub', how='left')\n",
    "    df.drop('Hub', axis = 1, inplace=True)\n",
    "    df.rename(columns={'Latitude' : 'End Latitude', \n",
    "                       'Longitude' : 'End Longitude'\n",
    "                      }, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Drop rows with nulls.</span>\n",
    "<span style='color:#52aec9'>Don't have any to drop right now.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nans(df):\n",
    "\n",
    "    if (sum(df.isnull().sum()) > 0):\n",
    "        print(df[df['End Latitude'].isnull() | df['Start Latitude'].isnull()])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Use appropriate datatypes.</span>\n",
    "<span style='color:#52aec9'>For example, fix Date/Time objects and cast Latitude and Longitude to floats.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_datatypes(df):\n",
    "    df['Start Latitude'] = df['Start Latitude'].astype(float)\n",
    "    df['Start Longitude'] = df['Start Longitude'].astype(float)\n",
    "    df['End Latitude'] = df['End Latitude'].astype(float)\n",
    "    df['End Longitude'] = df['End Longitude'].astype(float)\n",
    "\n",
    "    # Turn times in datetime\n",
    "    df['Start Time'] = pd.to_datetime(df['Start Time'])\n",
    "    df['End Time'] = pd.to_datetime(df['End Time'])\n",
    "\n",
    "    # CREATE dates in datetime\n",
    "    df['Start Date'] = df['Start Time'].dt.date\n",
    "    df['End Date'] = df['End Time'].dt.date\n",
    "\n",
    "    # Fix the durations\n",
    "    if df['Duration'].dtype == np.object:\n",
    "        df['Duration'] = df['Duration'].map(lambda cell: cell.replace(',',''))\n",
    "    df['Duration'] = df['Duration'].astype(float)\n",
    "    df['Duration'] = pd.to_timedelta(df['Duration'], unit='s')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Calculate distances.</span>\n",
    "<span style='color:#52aec9'>Poor approximation. If bike was checked-out and returned to same station, will be trivial distance.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_calc (row):\n",
    "    start = (row['Start Latitude'], row['Start Longitude'])\n",
    "    stop = (row['End Latitude'], row['End Longitude'])\n",
    "    return vincenty(start, stop).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distances(df):\n",
    "    df['Distance [Miles]'] = df.apply (lambda row: distance_calc (row),axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Reorder columns.</span>\n",
    "<span style='color:#52aec9'>Make order same as Atlanta data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_cols(df):\n",
    "    columns = ['Start Hub', 'Start Latitude', 'Start Longitude', 'Start Date',\n",
    "       'Start Time', 'End Hub', 'End Latitude', 'End Longitude', 'End Date',\n",
    "       'End Time', 'Bike Name', 'Distance [Miles]', 'Duration']\n",
    "\n",
    "    df = df.reindex(columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Drop trivial trips.</span>\n",
    "<span style='color:#52aec9'>Trivial trips have time less than 3 mins. We cannot drop for trivial distance, since we compute distance.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_trivial_trips_distance(df):\n",
    "    df = df[df[\"Distance [Miles]\"] > 0.02].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_trivial_trips_duration(df):\n",
    "    df = df[(df[\"Duration\"] >= pd.to_timedelta('00:03:00')) | (df['Start Hub'] != df['End Hub'])].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_trivial_trips(df):\n",
    "    global trivial_duration\n",
    "    global trivial_distance\n",
    "\n",
    "    rows = df.shape[0]\n",
    "#    df = drop_trivial_trips_duration(df)\n",
    "    rows_duration = df.shape[0]\n",
    "    trivial_duration += rows-rows_duration\n",
    "\n",
    "    # Calculated distance, don't drop\n",
    "    df = drop_trivial_trips_distance(df)\n",
    "    rows_distance = df.shape[0]\n",
    "    trivial_distance += rows_duration-rows_distance\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Drop outliers.</span>\n",
    "<ul>\n",
    "    <li><span style='color:#52aec9'>Only use trips near DC.</span></li> \n",
    "    <li><span style='color:#52aec9'>Only use trips no longer than 24 hours.</span></li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers_latlon(df):\n",
    "#     df = df[df[\"Start Latitude\"] < 33.9].copy()\n",
    "#     df = df[df[\"End Latitude\"] < 33.9].copy()\n",
    "#     df = df[df[\"Start Latitude\"] > 33.5].copy()\n",
    "#     df = df[df[\"End Latitude\"] > 33.5].copy()\n",
    "\n",
    "#     df = df[df[\"Start Longitude\"] < -83.0].copy()\n",
    "#     df = df[df[\"End Longitude\"] < -83.0].copy()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers_duration(df):\n",
    "    df = df[df[\"Duration\"] <= pd.to_timedelta('24:00:00')].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers_distance(df):\n",
    "    df_temp = df[df[\"Distance [Miles]\"] >= 100.0]\n",
    "    if df_temp.shape[0]:\n",
    "        print(\"Long trip: \", df_temp[['Start Latitude','Start Longitude', 'Start Time', \n",
    "                                     'End Latitude', 'End Longitude', 'End Time', \n",
    "                                     'Distance [Miles]', 'Duration']])\n",
    "    df = df[df[\"Distance [Miles]\"] < 100.0].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers(df):\n",
    "    global outliers_latlon\n",
    "    global outliers_duration\n",
    "    global outliers_distance\n",
    "    \n",
    "    rows = df.shape[0]\n",
    "    df = drop_outliers_latlon(df)\n",
    "    rows_latlon = df.shape[0]\n",
    "    outliers_latlon += rows - rows_latlon\n",
    "    \n",
    "    df = drop_outliers_duration(df)\n",
    "    rows_duration = df.shape[0]\n",
    "    outliers_duration += rows_latlon - rows_duration\n",
    "    \n",
    "    df = drop_outliers_distance(df)\n",
    "    rows_distance = df.shape[0]\n",
    "    outliers_distance += rows_duration - rows_distance\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#4095b5'>Pull all of the cleaning together.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, df_hubs=None):\n",
    "    global trivial_duration\n",
    "    global trivial_distance\n",
    "    global outliers_latlon\n",
    "    global outliers_duration\n",
    "    global outliers_distance\n",
    "\n",
    "    df = drop_columns(df)\n",
    "    df = rename_columns(df)\n",
    "    df = calc_latlong(df, df_hubs)\n",
    "    df = drop_nans(df)\n",
    "    df = clean_datatypes(df)\n",
    "    df = calc_distances(df)\n",
    "    df = reorder_cols(df)\n",
    "    df = drop_trivial_trips(df)\n",
    "    df = drop_outliers(df)\n",
    "\n",
    "    # Information about rows dropped\n",
    "    print(\"Trivial dur: {} dist: {}\".format(trivial_duration, \n",
    "                                                                              trivial_distance))\n",
    "    print(\"Outlier loc: {} dur: {} dist: {}\".format(outliers_latlon,\n",
    "                                                     outliers_duration,\n",
    "                                                     outliers_distance))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"hubs\"></a>\n",
    "## <span style='color:#3b748a'>III. Create hubs</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Load all rental data.</span></li>\n",
    "    <li><span style='color:#4095b5'>Create set of all hubs.</span></li>\n",
    "    <li><span style='color:#4095b5'>Write to csv.</span></li>\n",
    "    <li><span style='color:#4095b5'>Use <a href=\"http://www.mapdevelopers.com/batch_geocode_tool.php\">geocode tool</a> to determine lat/lon for each hub.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hubs(df, hubs):\n",
    "    hubs = hubs.union(set(df['Start station']), set(df['End station']))\n",
    "    \n",
    "    return hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    trip_data = ['2017Q3', '2017Q4',\n",
    "               '201801', '201802', '201803',\n",
    "               '201804', '201805', '201806',\n",
    "               '201807', '201808']\n",
    "\n",
    "    hubs = set()\n",
    "    for d in trip_data:\n",
    "        df_temp = pd.read_csv(\"../data/dc/\"+str(d)+\"-capitalbikeshare-tripdata.csv\")\n",
    "        hubs = clean_hubs(df_temp,hubs)\n",
    "        print(hubs)\n",
    "\n",
    "    df_hubs = pd.DataFrame(np.array(list(hubs)))\n",
    "    df_hubs.to_csv('../data/dc/hub-names.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"convert\"></a>\n",
    "## <span style='color:#3b748a'>IV. Extract July, Aug, Sep 2017 from 2017 Q3 data.</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Trip data is quarterly.</span></li>\n",
    "    <li><span style='color:#4095b5'>The file is too huge to easily use.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    d = \"2017Q3\"\n",
    "    df = pd.read_csv(\"../data/dc/\"+str(d)+\"-capitalbikeshare-tripdata.csv\")\n",
    "\n",
    "    # Turn times in datetime\n",
    "    df['Start Time'] = pd.to_datetime(df['Start date'])\n",
    "    df['End Time'] = pd.to_datetime(df['End date'])\n",
    "\n",
    "    # 2017Q3 = 2017-07-01, 2017-08-01, 2017-09-01\n",
    "    df7 = df[df['Start Time'] < datetime.strptime('2017-08-01 00:00:00', '%Y-%m-%d %H:%M:%S')].copy()\n",
    "    df7.drop(['Start Time', 'End Time'], axis=1, inplace=True)\n",
    "    print(df7.shape)\n",
    "    df7.to_csv('../data/dc/201707-capitalbikeshare-tripdata.csv', index=False)\n",
    "    \n",
    "    # 2017Q3 = 2017-07-01, 2017-08-01, 2017-09-01\n",
    "    df8 = df[df['Start Time'] < datetime.strptime('2017-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')].copy()\n",
    "    df8 = df8[df8['Start Time'] >= datetime.strptime('2017-08-01 00:00:00', '%Y-%m-%d %H:%M:%S')].copy()\n",
    "    df8.drop(['Start Time', 'End Time'], axis=1, inplace=True)\n",
    "    print(df8.shape)\n",
    "    df8.to_csv('../data/dc/201708-capitalbikeshare-tripdata.csv', index=False)\n",
    "    \n",
    "    # 2017Q3 = 2017-07-01, 2017-08-01, 2017-09-01\n",
    "    df9 = df[df['Start Time'] >= datetime.strptime('2017-09-01 00:00:00', '%Y-%m-%d %H:%M:%S')].copy()\n",
    "    df9.drop(['Start Time', 'End Time'], axis=1, inplace=True)\n",
    "    print(df9.shape)\n",
    "    df9.to_csv('../data/dc/201709-capitalbikeshare-tripdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"import\"></a>\n",
    "## <span style='color:#3b748a'>V. Import all data from Washington DC</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Need hub data to calculate latitude/longitude.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 201808-capitalbikeshare-tripdata\n",
    "# DC data is quarterly for 2017 and monthly for 2018\n",
    "trip_data = ['201709', '2017Q4',\n",
    "               '201801', '201802', '201803',\n",
    "               '201804', '201805', '201806',\n",
    "               '201807', '201808']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of DataFrames, one for each time period\n",
    "df_data = dict()\n",
    "for d in trip_data:\n",
    "    df_data[d] = pd.read_csv(\"../data/dc/\"+str(d)+\"-capitalbikeshare-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the hubs in order to lookup latitude/longitude\n",
    "df_hubs = pd.read_csv(\"../data/dc/hubs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"clean\"></a>\n",
    "\n",
    "## <span style='color:#3b748a'>VI. Clean all data from Washington DC.</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>For now, drop most of the columns.</span></li>\n",
    "    <li><span style='color:#4095b5'>Drop the trivial trips.</span></li>\n",
    "    <li><span style='color:#4095b5'>Drop the outliers.</span></li>\n",
    "    <li><span style='color:#4095b5'>Use appropriate coumn types.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the data:\n",
      "Month: 201709 \n",
      "Rows: 391371\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 15648\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 375723\t Cols: 13\t NaNs: 0\n",
      "Month: 2017Q4 \n",
      "Rows: 815264\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 40559\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 790353\t Cols: 13\t NaNs: 0\n",
      "Month: 201801 \n",
      "Rows: 168590\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 44346\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 164803\t Cols: 13\t NaNs: 0\n",
      "Month: 201802 \n",
      "Rows: 182378\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 48997\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 177727\t Cols: 13\t NaNs: 0\n",
      "Month: 201803 \n",
      "Rows: 238998\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 57879\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 230116\t Cols: 13\t NaNs: 0\n",
      "Month: 201804 \n",
      "Rows: 328907\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 73433\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 313353\t Cols: 13\t NaNs: 0\n",
      "Month: 201805 \n",
      "Rows: 374115\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 91406\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 356142\t Cols: 13\t NaNs: 0\n",
      "Month: 201806 \n",
      "Rows: 392338\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 110001\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 373743\t Cols: 13\t NaNs: 0\n",
      "Month: 201807 \n",
      "Rows: 404761\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 132464\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 382298\t Cols: 13\t NaNs: 0\n",
      "Month: 201808 \n",
      "Rows: 403866\t Cols: 9\t NaNs: 0\n",
      "Trivial dur: 0 dist: 151583\n",
      "Outlier loc: 0 dur: 0 dist: 0\n",
      "Rows: 384747\t Cols: 13\t NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "# For each month, clean the DataFrame\n",
    "print(\"Cleaning the data:\")\n",
    "for d in trip_data:\n",
    "    print(\"Month: {} \\nRows: {}\\t Cols: {}\\t NaNs: {}\".format(d, \n",
    "                                                    df_data[d].shape[0], \n",
    "                                                    df_data[d].shape[1], \n",
    "                                                    sum(df_data[d].isnull().sum())))\n",
    "    df_data[d] = clean_df(df_data[d], df_hubs)\n",
    "    check_data(df_data[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Hub</th>\n",
       "      <th>Start Latitude</th>\n",
       "      <th>Start Longitude</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Hub</th>\n",
       "      <th>End Latitude</th>\n",
       "      <th>End Longitude</th>\n",
       "      <th>End Date</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Bike Name</th>\n",
       "      <th>Distance [Miles]</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129350</th>\n",
       "      <td>17th &amp; K St NW</td>\n",
       "      <td>38.902755</td>\n",
       "      <td>-77.038638</td>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>2018-08-10 18:30:41</td>\n",
       "      <td>17th &amp; K St NW / Farragut Square</td>\n",
       "      <td>38.901957</td>\n",
       "      <td>-77.038995</td>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>2018-08-10 18:31:42</td>\n",
       "      <td>W21702</td>\n",
       "      <td>0.058342</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61460</th>\n",
       "      <td>3rd &amp; Tingey St SE</td>\n",
       "      <td>38.874890</td>\n",
       "      <td>-77.000030</td>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>2018-08-05 17:18:37</td>\n",
       "      <td>M St &amp; New Jersey Ave SE</td>\n",
       "      <td>38.876539</td>\n",
       "      <td>-77.004185</td>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>2018-08-05 17:19:37</td>\n",
       "      <td>W23344</td>\n",
       "      <td>0.251264</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204607</th>\n",
       "      <td>Columbia &amp; Ontario Rd NW</td>\n",
       "      <td>38.922184</td>\n",
       "      <td>-77.040177</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>2018-08-16 16:47:59</td>\n",
       "      <td>Adams Mill &amp; Columbia Rd NW</td>\n",
       "      <td>38.923044</td>\n",
       "      <td>-77.042555</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>2018-08-16 16:48:59</td>\n",
       "      <td>W23291</td>\n",
       "      <td>0.141233</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172363</th>\n",
       "      <td>11th &amp; F St NW</td>\n",
       "      <td>38.897857</td>\n",
       "      <td>-77.054845</td>\n",
       "      <td>2018-08-14</td>\n",
       "      <td>2018-08-14 10:44:14</td>\n",
       "      <td>10th &amp; G St NW</td>\n",
       "      <td>38.898700</td>\n",
       "      <td>-77.026488</td>\n",
       "      <td>2018-08-14</td>\n",
       "      <td>2018-08-14 10:45:15</td>\n",
       "      <td>W20761</td>\n",
       "      <td>1.529667</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>20th St &amp; Virginia Ave NW</td>\n",
       "      <td>38.894264</td>\n",
       "      <td>-77.047115</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>2018-08-08 17:51:35</td>\n",
       "      <td>20th &amp; E St NW</td>\n",
       "      <td>38.895321</td>\n",
       "      <td>-77.044278</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>2018-08-08 17:52:35</td>\n",
       "      <td>W20604</td>\n",
       "      <td>0.169445</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Start Hub  Start Latitude  Start Longitude  \\\n",
       "129350             17th & K St NW       38.902755       -77.038638   \n",
       "61460          3rd & Tingey St SE       38.874890       -77.000030   \n",
       "204607   Columbia & Ontario Rd NW       38.922184       -77.040177   \n",
       "172363             11th & F St NW       38.897857       -77.054845   \n",
       "99991   20th St & Virginia Ave NW       38.894264       -77.047115   \n",
       "\n",
       "        Start Date          Start Time                           End Hub  \\\n",
       "129350  2018-08-10 2018-08-10 18:30:41  17th & K St NW / Farragut Square   \n",
       "61460   2018-08-05 2018-08-05 17:18:37          M St & New Jersey Ave SE   \n",
       "204607  2018-08-16 2018-08-16 16:47:59       Adams Mill & Columbia Rd NW   \n",
       "172363  2018-08-14 2018-08-14 10:44:14                    10th & G St NW   \n",
       "99991   2018-08-08 2018-08-08 17:51:35                    20th & E St NW   \n",
       "\n",
       "        End Latitude  End Longitude    End Date            End Time Bike Name  \\\n",
       "129350     38.901957     -77.038995  2018-08-10 2018-08-10 18:31:42    W21702   \n",
       "61460      38.876539     -77.004185  2018-08-05 2018-08-05 17:19:37    W23344   \n",
       "204607     38.923044     -77.042555  2018-08-16 2018-08-16 16:48:59    W23291   \n",
       "172363     38.898700     -77.026488  2018-08-14 2018-08-14 10:45:15    W20761   \n",
       "99991      38.895321     -77.044278  2018-08-08 2018-08-08 17:52:35    W20604   \n",
       "\n",
       "        Distance [Miles] Duration  \n",
       "129350          0.058342 00:01:00  \n",
       "61460           0.251264 00:01:00  \n",
       "204607          0.141233 00:01:00  \n",
       "172363          1.529667 00:01:00  \n",
       "99991           0.169445 00:01:00  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['201808'].sort_values(by='Duration').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"merge\"></a>\n",
    "\n",
    "## <span style='color:#3b748a'>VII. Merge the DataFrames into 1 big DataFrame</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 0\n",
    "df = pd.DataFrame()\n",
    "for d in trip_data:\n",
    "    n_rows += df_data[d].shape[0]\n",
    "    df = df.append(df_data[d])\n",
    "\n",
    "if n_rows != df.shape[0]:\n",
    "    print(\"There is a problem with the DataFrame merge!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"explore\"></a>\n",
    "\n",
    "## <span style='color:#3b748a'> VIII. Explore the data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    check_data(df)\n",
    "    check_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"write\"></a>\n",
    "\n",
    "## <span style='color:#3b748a'>IX. Write the full DataFrame to a csv file.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/dc/trips_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
